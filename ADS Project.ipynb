{"cells":[{"cell_type":"markdown","source":["##HandWritten Digit Recognition using SVM, CNN with TensorFlow and Keras"],"metadata":{}},{"cell_type":"markdown","source":["### MNIST Dataset\nThe MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems. The database is also widely used for training and testing in the field of machine learning. It was created by \"re-mixing\" the samples from NIST's original datasets. These images were normalized in size and centered. Each image is in a 28x28 square (784 pixels). 60,000 images were used to train a model and 10,000 were used to test it."],"metadata":{}},{"cell_type":"markdown","source":["### Digit Recognition using Convolutional Layer Networks"],"metadata":{}},{"cell_type":"markdown","source":["##### Imports"],"metadata":{}},{"cell_type":"code","source":["from matplotlib import pyplot \nimport numpy"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["We need to import several things from Keras."],"metadata":{}},{"cell_type":"code","source":["from keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.utils import np_utils\nfrom keras.layers import Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["# fix dimension ordering issue\nfrom keras import backend as K\nK.set_image_dim_ordering('th')\n# fix random seed for reproducibility\nseed = 7\nnumpy.random.seed(seed)\n# load data\n(X_train, y_train), (X_test, y_test) = mnist.load_data()"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# reshape to be [samples][channels][width][height]\nX_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\nX_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["# normalize inputs from 0-255 to 0-1\nX_train = X_train / 255\nX_test = X_test / 255"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["The class-labels are One-Hot encoded, which means that each label is a vector with 10 elements, all of which are zero except for one element. The index of this one element is the class-number, that is, the digit shown in the associated image."],"metadata":{}},{"cell_type":"code","source":["# one hot encode outputs\ny_train = np_utils.to_categorical(y_train)\ny_test = np_utils.to_categorical(y_test)\nnum_classes = y_test.shape[1]"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["#### Simple Convolutional Neural Network\nHere we will be using one convolutional layer, one max pooling layer and one hidden layer"],"metadata":{}},{"cell_type":"markdown","source":["##### The neural network structure is shown below\n\nVisible Layer (1x28x28 Inputs) >> Convolutional Layer (32 maps, 5x5) >> Max Pooling Layer (2x2) >> Dropout Layer (20%) >> Flatten Layer >> Hidden Layer (128 Neurons) >> Output Layer (10 Outputs)"],"metadata":{}},{"cell_type":"markdown","source":["#####Sequential Model\nThe Keras API has two modes of constructing Neural Networks. The simplest is the Sequential Model which only allows for the layers to be added in sequence."],"metadata":{}},{"cell_type":"code","source":["# define a simple CNN model\ndef baseline_model():\n\t# create model\n    # The Keras API has two modes of constructing Neural Networks. The simplest is the Sequential Model which only allows for the layers to be added in sequence.\n\tmodel = Sequential()\n    # Convolutional layer with ReLU-activation and max-pooling.\n\tmodel.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\tmodel.add(Dropout(0.2))\n    # Flatten the 4-rank output of the convolutional layers to 2-rank that can be input to a fully-connected / dense layer.\n\tmodel.add(Flatten())\n    # First fully-connected / dense layer with ReLU-activation.\n\tmodel.add(Dense(128, activation='relu'))\n    # Last fully-connected / dense layer with softmax-activation for use in classification.\n\tmodel.add(Dense(num_classes, activation='softmax'))\n\t# Compile model\n    # The Neural Network has now been defined and must be finalized by adding a loss-function, optimizer and performance metrics. This is called model \"compilation\" in Keras.\n    # For a classification-problem such as MNIST which has 10 possible classes, we need to use the loss-function called categorical_crossentropy. The performance metric we are     # interested in is the classification accuracy.\n\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\treturn model\n"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["###### Build, Fit and Final evalution of the model"],"metadata":{}},{"cell_type":"markdown","source":["Here the epochs are given 10, which means the function iterates 10 times with a batch size of 200."],"metadata":{}},{"cell_type":"code","source":["# build the model\nmodel = baseline_model()\n# Fit the model\nmodel.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n# Final evaluation of the model\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"CNN Error for the Simple Convolutional Network is: %.2f%%\" % (100-scores[1]*100))"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["##### Summary of a model"],"metadata":{}},{"cell_type":"code","source":["model.summary()"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["### Large Convolutional Neural Network\nHere we will be using Two convolutional layers, Two max pooling layers and Two hidden layers"],"metadata":{}},{"cell_type":"markdown","source":["##### The neural network structure is shown below\n\nVisible Layer (1x28x28 Inputs) >> Convolutional Layer (30 maps, 5x5) >> Max Pooling Layer (2x2) >> Convolutional Layer (15 maps, 3x3) >> Max Pooling Layer (2x2) >> Dropout Layer (20%) >> Hidden Layer (128 Neurons) >> Hidden Layer (50 Neurons) >> Output Layer (10 Outputs"],"metadata":{}},{"cell_type":"markdown","source":["#######Sequential Model\nThe Keras API has two modes of constructing Neural Networks. The simplest is the Sequential Model which only allows for the layers to be added in sequence."],"metadata":{}},{"cell_type":"code","source":["# define a simple CNN model\ndef larger_model():\n\t# create model\n    # The Keras API has two modes of constructing Neural Networks. The simplest is the Sequential Model which only allows for the layers to be added in sequence.\n\tmodel = Sequential()\n    # First convolutional layer with ReLU-activation and max-pooling.\n\tmodel.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n    # Second convolutional layer with ReLU-activation and max-pooling.\n\tmodel.add(Conv2D(15, (3, 3), activation='relu'))\n\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\tmodel.add(Dropout(0.2))\n    # Flatten the 4-rank output of the convolutional layers to 2-rank that can be input to a fully-connected / dense layer.\n\tmodel.add(Flatten())\n    # First fully-connected / dense layer with ReLU-activation.\n\tmodel.add(Dense(128, activation='relu'))\n    # Second fully-connected / dense layer with ReLU-activation.\n\tmodel.add(Dense(50, activation='relu'))\n    # Last fully-connected / dense layer with softmax-activation for use in classification.\n\tmodel.add(Dense(num_classes, activation='softmax'))\n\t# Compile model\n    # The Neural Network has now been defined and must be finalized by adding a loss-function, optimizer and performance metrics. This is called model \"compilation\" in Keras.\n    # For a classification-problem such as MNIST which has 10 possible classes, we need to use the loss-function called categorical_crossentropy. The performance metric we are     # interested in is the classification accuracy.\n\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\treturn model\n"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":["###### Build, Fit and final evaluation of the model"],"metadata":{}},{"cell_type":"markdown","source":["Here the epochs are given 10, which means the function iterates 10 times with a batch size of 200."],"metadata":{}},{"cell_type":"code","source":["# build the model\nmodel = larger_model()\n# Fit the model\nmodel.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n# Final evaluation of the model\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"CNN Error for the Large Convolutional Network is: %.2f%%\" % (100-scores[1]*100))"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":["### Large Convolutional Neural network with image flip of degree 180\nDifferent people write in different angles. Here we randomly rotate images up to 180 degrees."],"metadata":{}},{"cell_type":"code","source":["# Simple CNN for the MNIST Dataset\nimport numpy\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.utils import np_utils\n# fix dimension ordering issue\nfrom keras import backend as K\nK.set_image_dim_ordering('th')\n# fix random seed for reproducibility\nseed = 7\nnumpy.random.seed(seed)\n# load data\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n# reshape to be [samples][channels][width][height]\nX_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\nX_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n# normalize inputs from 0-255 to 0-1\nX_train = X_train / 255\nX_test = X_test / 255\n# one hot encode outputs\ny_train = np_utils.to_categorical(y_train)\ny_test = np_utils.to_categorical(y_test)\nnum_classes = y_test.shape[1]\n# define data preparation\ndatagen = ImageDataGenerator(rotation_range=180)\n\n\n\n\n\n"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["\n# define a simple CNN model\ndef baseline_model():\n\t# create model\n\tmodel = Sequential()\n\tmodel.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\tmodel.add(Dropout(0.2))\n\tmodel.add(Flatten())\n\tmodel.add(Dense(128, activation='relu'))\n\tmodel.add(Dense(num_classes, activation='softmax'))\n\t# Compile model\n\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\treturn model\n# build the model\nmodel = baseline_model()\n# Fit the model\nmodel.fit_generator(datagen.flow(X_train.reshape(60000,1,28,28), y_train, batch_size=200), validation_data=(X_test.reshape(10000,1,28,28), y_test), epochs=10)\n"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["# Final evaluation of the model\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"CNN Error for Large Convolutional Network with image flip of degree 180: %.2f%%\" % (100-scores[1]*100))"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["model.summary()"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":["### Support Vector Machine(SVM)"],"metadata":{}},{"cell_type":"markdown","source":["##### Imports"],"metadata":{}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\nimport numpy as np\nimport time\nimport datetime as dt"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["#fetch original mnist dataset\nfrom sklearn.datasets import fetch_mldata"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["# Import datasets, classifiers and performance metrics\nfrom sklearn import datasets, svm, metrics"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"markdown","source":["##### Fetching of data from MNIST"],"metadata":{}},{"cell_type":"code","source":["mnist = fetch_mldata('MNIST original', data_home='./')"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"markdown","source":["##### Looking up keys present in data"],"metadata":{}},{"cell_type":"code","source":["\nmnist.keys()"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":["#data field is 70k x 784 array, each row represents pixels from 28x28=784 image\nimages = mnist.data\ntargets = mnist.target"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"code","source":["#full dataset classification\nX_data = images/255.0\nY = targets"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"code","source":["#split data to train and test\n#from sklearn.cross_validation import train_test_split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_data, Y, test_size=0.15, random_state=42)"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"code","source":["# Create a classifier: a support vector classifier\n\nparam_C = 5\nparam_gamma = 0.05\nclassifier = svm.SVC(C=param_C,gamma=param_gamma)\n\n# We learn the digits on train part\nstart_time = dt.datetime.now()\nprint('Start learning at {}'.format(str(start_time)))\nclassifier.fit(X_train, y_train)\nend_time = dt.datetime.now() \nprint('Stop learning {}'.format(str(end_time)))\nelapsed_time= end_time - start_time\nprint('Elapsed learning {}'.format(str(elapsed_time)))\nexpected = y_test\npredicted = classifier.predict(X_test)\nprint(\"Classification report for classifier %s:\\n%s\\n\"\n      % (classifier, metrics.classification_report(expected, predicted)))\n      \ncm = metrics.confusion_matrix(expected, predicted)\nprint(\"Confusion matrix:\\n%s\" % cm)\n\nprint(\"Accuracy={}\".format(metrics.accuracy_score(expected, predicted)))"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"markdown","source":["##### Citations"],"metadata":{}},{"cell_type":"markdown","source":["https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/03C_Keras_API.ipynb"],"metadata":{}},{"cell_type":"markdown","source":["## Results"],"metadata":{}},{"cell_type":"markdown","source":["##### Accuracy of Finding the digit using Simple Convolutional Layer                                  : 99.07\n\n##### Accuracy of Finding the digit using Large Convolutional Layer                                   : 99.26\n\n##### Accuracy of Finding the digit using Large Convolutional Layer with image flip of degree 180     : 96.46 %\n\n##### Accuracy of Finding the digit using Support Vector Machine (SVM)                                : 98.52 %"],"metadata":{}},{"cell_type":"markdown","source":["The text in the document by Rajasekhar Reddy Duddugunta is licensed under CC BY 3.0 https://creativecommons.org/licenses/by/3.0/us/\n\nThe code in the document by Rajasekhar Reddy Duddugunta is licensed under the MIT License https://opensource.org/licenses/MIT\n\nCopyright 2018 Rajasekhar Reddy Duddugunta\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":52}],"metadata":{"name":"ADS Project","notebookId":647342613821444},"nbformat":4,"nbformat_minor":0}
